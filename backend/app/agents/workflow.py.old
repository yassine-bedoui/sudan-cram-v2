from datetime import datetime
import json
import os
from typing import Any, Dict, List, Optional

from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END

from app.agents.state import SudanCRAMState
from app.services.vector_store import VectorStore


# ---- 1. LLM + Vector Store setup ----

llm = ChatOllama(
    model=os.getenv("OLLAMA_MODEL", "qwen2.5:14b"),
    base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
    temperature=0.7,
)

vector_store = VectorStore()


# ---- Small helper: build canonical events timeline ----

def _build_events_timeline_from_retrieved(
    retrieved_events: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """Turn raw vector-store hits into a canonical events timeline."""
    events_timeline: List[Dict[str, Any]] = []
    for e in sorted(
        retrieved_events,
        key=lambda x: x.get("metadata", {}).get("date", ""),
    ):
        meta = e.get("metadata", {})
        events_timeline.append(
            {
                "date": meta.get("date"),
                "source": meta.get("source", "GDELT"),
                "region": meta.get("region"),
                "event_type": meta.get("event_type"),
                "actors": meta.get("actors", []),
                "fatalities": meta.get("fatalities"),
            }
        )
    return events_timeline


# ---- 2. Nodes ----

def rag_retrieval_node(state: SudanCRAMState) -> SudanCRAMState:
    """Retrieve relevant events from Qdrant for the given region."""
    print("\nðŸ” RAG Retrieval...")

    region = state["region"]

    # First: try region-focused search
    region_query = f"conflict events in {region}"
    region_results = vector_store.semantic_search(
        query=region_query,
        filters={"region": region},
        top_k=20,
    )

    if region_results:
        results = region_results
        state["messages"].append(
            f"Retrieved {len(results)} region-focused events for {region}"
        )
    else:
        # Fallback: national context if nothing region-specific is found
        results = vector_store.semantic_search(
            query=region_query,
            filters=None,
            top_k=20,
        )
        state["messages"].append(
            "No region-specific matches; used Sudan-wide context instead"
        )
        state["messages"].append(
            f"Retrieved {len(results)} events for region {region}"
        )

    state["retrieved_events"] = results

    # âœ… Build canonical events timeline early so all downstream nodes see it
    state["events"] = _build_events_timeline_from_retrieved(results)

    return state


def event_extractor_node(state: SudanCRAMState) -> SudanCRAMState:
    """Extract structured events from raw text, using retrieved events as context."""
    print("\nðŸ“ Event Extractor...")

    raw = state.get("raw_data")
    if not raw:
        state["extracted_events"] = None
        state["messages"].append("No raw_data provided; skipping event extraction")
        return state

    # Use a few retrieved events as context for the LLM
    context_lines = []
    for e in state.get("retrieved_events", [])[:5]:
        meta = e.get("metadata", {})
        event_type = meta.get("event_type", "unknown")
        actors = meta.get("actors", [])
        context_lines.append(f"- {event_type}: {actors}")

    context = "\n".join(context_lines)

    prompt = f"""
You are an analyst extracting conflict events from reports.

CONTEXT (recent similar events):
{context}

TEXT TO ANALYZE:
{raw}

Extract events as JSON. Use this exact schema:

{{
  "events": [
    {{
      "event_type": "string",
      "date": "YYYY-MM-DD or null",
      "location": "string or null",
      "actors": ["Actor A", "Actor B"],
      "fatalities": 0
    }}
  ],
  "confidence": 0.0
}}
"""

    response = llm.invoke(
        [
            SystemMessage(content="Extract conflict events from the text. Output JSON ONLY."),
            HumanMessage(content=prompt),
        ]
    )

    try:
        result = json.loads(response.content)
        state["extracted_events"] = result
        n = len(result.get("events", []))
        state["messages"].append(f"Extracted {n} events from raw_data")
    except Exception as e:
        state["extracted_events"] = {"error": "parse_failed", "raw": response.content}
        state["messages"].append(f"âš ï¸ Event extraction JSON parse failed: {e}")

    return state


def trend_analyst_node(state: SudanCRAMState) -> SudanCRAMState:
    """Analyze trends using the retrieved events timeline."""
    print("\nðŸ“Š Trend Analyst...")

    # Build a simple timeline summary directly from retrieved_events
    timeline_lines: List[str] = []
    for e in sorted(
        state.get("retrieved_events", []),
        key=lambda x: x.get("metadata", {}).get("date", ""),
    )[:15]:
        meta = e.get("metadata", {})
        date = meta.get("date", "unknown_date")
        event_type = meta.get("event_type", "unknown_type")
        fatalities = meta.get("fatalities")
        if fatalities is None:
            fat_str = "fatalities unknown"
        else:
            fat_str = f"{fatalities} fatalities"
        timeline_lines.append(f"{date}: {event_type} ({fat_str})")

    timeline = "\n".join(timeline_lines)

    prompt = f"""
You are a conflict trend analyst for Sudan.

REGION: {state['region']}

EVENT TIMELINE:
{timeline}

Analyze trends and produce JSON ONLY in this schema:

{{
  "trend_classification": "ESCALATING" | "STABLE" | "DEESCALATING" | "VOLATILE",
  "drivers": ["short bullet point string", "..."],
  "forecast_7_days": {{
    "armed_clash_likelihood": 0-100,
    "civilian_targeting_likelihood": 0-100
  }},
  "confidence": "LOW" | "MEDIUM" | "HIGH"
}}
"""

    response = llm.invoke(
        [
            SystemMessage(content="Analyze conflict trends and output JSON ONLY."),
            HumanMessage(content=prompt),
        ]
    )

    try:
        result = json.loads(response.content)
        state["trend_analysis"] = result
        state["messages"].append(
            f"Trend classification: {result.get('trend_classification', 'UNKNOWN')}"
        )
    except Exception as e:
        state["trend_analysis"] = {"error": "parse_failed", "raw": response.content}
        state["messages"].append(f"âš ï¸ Trend analysis JSON parse failed: {e}")

    return state


def scenario_generator_node(state: SudanCRAMState) -> SudanCRAMState:
    """Generate intervention scenarios."""
    print("\nðŸ”® Scenario Generator...")

    interventions = state.get("interventions")
    if not interventions:
        state["scenarios"] = None
        state["messages"].append(
            "No interventions provided; skipping scenario generation"
        )
        return state

    trend = state.get("trend_analysis")

    prompt = f"""
You are advising on conflict response options in {state['region']}.

CURRENT TREND (may be null):
{json.dumps(trend, ensure_ascii=False, indent=2)}

INTERVENTIONS TO EVALUATE:
{chr(10).join(f"- {i}" for i in interventions)}

Return JSON ONLY with this schema:

{{
  "scenarios": [
    {{
      "intervention": "string",
      "optimistic": {{
        "description": "string",
        "success_probability": 0-100
      }},
      "pessimistic": {{
        "description": "string",
        "risk_probability": 0-100
      }},
      "recommendation": "PROCEED" | "MODIFY" | "AVOID"
    }}
  ]
}}
"""

    response = llm.invoke(
        [
            SystemMessage(content="Generate policy scenarios and output JSON ONLY."),
            HumanMessage(content=prompt),
        ]
    )

    try:
        result = json.loads(response.content)
        state["scenarios"] = result
        n = len(result.get("scenarios", []))
        state["messages"].append(f"Generated {n} scenarios")
    except Exception as e:
        state["scenarios"] = {"error": "parse_failed", "raw": response.content}
        state["messages"].append(f"âš ï¸ Scenario generation JSON parse failed: {e}")

    return state


def consistency_checker_node(state: SudanCRAMState) -> SudanCRAMState:
    """Check for contradictions and produce an overall confidence score."""
    print("\nâœ… Consistency Checker...")

    payload = {
        "events": state.get("events"),
        "trends": state.get("trend_analysis"),
        "scenarios": state.get("scenarios"),
    }

    prompt = f"""
You are checking internal consistency of an analysis.

DATA:
{json.dumps(payload, ensure_ascii=False, indent=2)}

Identify contradictions or weak assumptions.

Return JSON ONLY:

{{
  "validation_status": "PASSED" | "WARNING" | "FAILED",
  "issues": [
    {{
      "type": "INCONSISTENCY" | "DATA_GAP",
      "description": "string",
      "severity": "LOW" | "MEDIUM" | "HIGH"
    }}
  ],
  "overall_confidence": 0.0-1.0
}}
"""

    response = llm.invoke(
        [
            SystemMessage(content="Validate consistency and output JSON ONLY."),
            HumanMessage(content=prompt),
        ]
    )

    try:
        result = json.loads(response.content)
        state["validation"] = result
        state["confidence_score"] = float(result.get("overall_confidence", 0.5))
        state["messages"].append(
            f"Validation: {result.get('validation_status', 'UNKNOWN')} "
            f"(confidence={state['confidence_score']:.2f})"
        )
    except Exception as e:
        state["validation"] = {"error": "parse_failed", "raw": response.content}
        state["confidence_score"] = 0.5
        state["messages"].append(f"âš ï¸ Validation JSON parse failed: {e}")

    return state


def human_approval_node(state: SudanCRAMState) -> SudanCRAMState:
    """Decide if human approval is required based on confidence."""
    print("\nðŸ‘¤ Human Approval Check...")

    conf = state.get("confidence_score", 0.0)

    if conf < 0.7:
        state["human_approval_required"] = True
        state["approval_status"] = "pending"
        state["messages"].append(
            f"âš ï¸ Human  approval requireed (confidence={conf:.2f})"
        )
    else:
        state["human_approval_required"] = False
        state["approval_status"] = "auto-approved"
        state["messages"].append(f"âœ… Auto-approved (confidence={conf:.2f})")

    return state


def should_request_human_input(state: SudanCRAMState) -> str:
    """
    Routing function for LangGraph conditional edge.

    Use the same confidence threshold as human_approval_node.
    """
    conf = state.get("confidence_score", 0.0)
    return "request_approval" if conf < 0.7 else "finalize"


# ---- 3. Graph wiring ----

builder = StateGraph(SudanCRAMState)

builder.add_node("rag_retrieval", rag_retrieval_node)
builder.add_node("event_extractor", event_extractor_node)
builder.add_node("trend_analyst", trend_analyst_node)
builder.add_node("scenario_generator", scenario_generator_node)
builder.add_node("consistency_checker", consistency_checker_node)
builder.add_node("human_approval", human_approval_node)

builder.set_entry_point("rag_retrieval")
builder.add_edge("rag_retrieval", "event_extractor")
builder.add_edge("event_extractor", "trend_analyst")
builder.add_edge("trend_analyst", "scenario_generator")
builder.add_edge("scenario_generator", "consistency_checker")

builder.add_conditional_edges(
    "consistency_checker",
    should_request_human_input,
    {
        "request_approval": "human_approval",
        "finalize": END,
    },
)

app = builder.compile()


# ---- 4. Explainability helper ----

def _build_explainability_payload(state: SudanCRAMState) -> Dict[str, Any]:
    events = state.get("events") or []
    trends = state.get("trend_analysis") or {}
    scenarios = state.get("scenarios") or {}
    validation = state.get("validation") or {}

    # Time span in days based on events
    if events:
        dates = [e.get("date") for e in events if e.get("date")]
        try:
            parsed = [datetime.fromisoformat(d) for d in dates]
            time_span_days = (max(parsed) - min(parsed)).days
        except Exception:
            time_span_days = None
    else:
        time_span_days = None

    # Scenario stats
    scenario_list = scenarios.get("scenarios") or []
    max_success = None
    max_risk = None
    recs: List[str] = []
    for s in scenario_list:
        optimistic = (s or {}).get("optimistic") or {}
        pessimistic = (s or {}).get("pessimistic") or {}
        success_prob = optimistic.get("success_probability")
        risk_prob = pessimistic.get("risk_probability")
        if success_prob is not None:
            max_success = (
                success_prob
                if max_success is None
                else max(max_success, success_prob)
            )
        if risk_prob is not None:
            max_risk = (
                risk_prob if max_risk is None else max(max_risk, risk_prob)
            )
        rec = (s or {}).get("recommendation")
        if rec:
            recs.append(rec)

    explainability: Dict[str, Any] = {
        "input": {
            "region": state.get("region"),
            "has_raw_data": bool(state.get("raw_data")),
            "interventions_count": len(state.get("interventions") or []),
            "interventions": state.get("interventions") or [],
        },
        "retrieval": {
            "total_events_considered": len(events),
            "sources": {
                "GDELT": len(events),
            },
            "time_span_days": time_span_days,
        },
        "trend": {
            "trend_classification": trends.get("trend_classification"),
            "confidence_label": trends.get("confidence"),
            "drivers": trends.get("drivers") or [],
            "forecast_7_days": trends.get("forecast_7_days") or {},
        },
        "scenarios": {
            "num_scenarios": len(scenario_list),
            "recommendations": recs,
            "max_success_probability": max_success,
            "max_risk_probability": max_risk,
        },
        "validation": {
            "status": validation.get("validation_status"),
            "issue_count": len(validation.get("issues") or []),
            "issues": validation.get("issues") or [],
            "overall_confidence": validation.get("overall_confidence"),
        },
        "meta": {
            "pipeline_confidence_score": state.get("confidence_score"),
            "timestamp": datetime.utcnow().isoformat(),
        },
    }

    return explainability


# ---- 5. Public API ----

def run_analysis(
    region: str,
    raw_data: Optional[str] = None,
    interventions: Optional[List[str]] = None,
) -> Dict[str, Any]:
    """Entry point used by both CLI and FastAPI to run the workflow."""
    print("\n" + "=" * 60)
    print(f"ðŸš€ LANGGRAPH WORKFLOW START: {region}")
    print("=" * 60)

    initial_state: SudanCRAMState = {
        "region": region,
        "raw_data": raw_data,
        "interventions": interventions or [],
        "retrieved_events": [],
        "events": [],
        "extracted_events": None,
        "trend_analysis": None,
        "scenarios": None,
        "validation": None,
        "human_approval_required": False,
        "approval_status": None,
        "messages": [],
        "confidence_score": 0.0,
    }

    final_state = app.invoke(initial_state)

    # Ensure events timeline is set from retrieved_events (authoritative)
    retrieved_events = final_state.get("retrieved_events") or []
    final_state["events"] = _build_events_timeline_from_retrieved(retrieved_events)

    print("\n" + "=" * 60)
    print("âœ… WORKFLOW COMPLETE")
    print("=" * 60)

    # Deduplicate messages while preserving order
    seen = set()
    dedup_messages: List[str] = []
    for m in final_state.get("messages", []):
        if m not in seen:
            seen.add(m)
            dedup_messages.append(m)

    explainability = _build_explainability_payload(final_state)
    timestamp = explainability["meta"]["timestamp"]

    return {
        "region": final_state["region"],
        "raw_data": final_state.get("raw_data"),
        "interventions": final_state.get("interventions") or [],
        "retrieved_events": retrieved_events,
        "events": final_state.get("events") or [],
        "trend_analysis": final_state.get("trend_analysis"),
        "scenarios": final_state.get("scenarios"),
        "validation": final_state.get("validation"),
        "approval_status": final_state.get("approval_status"),
        "confidence_score": final_state.get("confidence_score", 0.0),
        "messages": dedup_messages,
        "timestamp": timestamp,
        "explainability": explainability,
    }
