"""
âœ… CONFLICT PRONENESS v2 - ALL 4 INDICATORS:
1. INCIDENTS (event frequency) - 35%
2. CAUSES (high-risk events: political, communal, resource) - 30%
3. ACTORS (number of distinct parties) - 20%
4. TREND (recent change in conflict pattern) - 15%
Plus Climate vulnerability weight
"""

import pandas as pd
import numpy as np
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data" / "processed"

ACLED_FILE = DATA_DIR / "acled_with_causes.csv"
CLIMATE_FILE = DATA_DIR / "climate_risk_cdi_v2_real.csv"
OUTPUT_FILE = DATA_DIR / "conflict_proneness_v2.csv"

# ==================== WEIGHTS ====================
WEIGHTS = {
    'incidents': 0.35,        # Event frequency (ALL 4 INDICATORS)
    'causes': 0.30,           # High-risk causes breakdown
    'actors': 0.20,           # Conflict parties involved
    'trend': 0.15,            # Recent trend change
    'climate': 0.25,          # Climate as context factor (separate)
}

# ==================== HELPER FUNCTIONS ====================
def calculate_all_4_indicators(df_acled):
    """
    Calculate all 4 conflict proneness sub-indicators per state
    Returns dict: {state: {incidents, causes_pct, actors, trend_delta}}
    """
    indicators_by_state = {}
    
    for admin1 in df_acled['ADMIN1'].unique():
        state_data = df_acled[df_acled['ADMIN1'] == admin1]
        
        # INDICATOR 1: INCIDENTS (frequency of all events)
        total_events = len(state_data)
        
        # INDICATOR 2: CAUSES (% of high-risk events)
        high_risk_events = state_data['cause_class'].notna().sum()
        causes_pct = (high_risk_events / max(total_events, 1)) * 100
        
        # INDICATOR 3: ACTORS (distinct parties/organizations)
        if 'ACTOR1' in state_data.columns and 'ACTOR2' in state_data.columns:
            unique_actors = set(state_data['ACTOR1'].unique()) | set(state_data['ACTOR2'].unique())
            num_actors = len(unique_actors) - 1  # Exclude NaN
        else:
            num_actors = 1  # Default if actors not available
        
        # INDICATOR 4: TREND (slope of event frequency over time)
        if 'event_date' in state_data.columns:
            state_data_sorted = state_data.sort_values('event_date')
            first_half = len(state_data_sorted[:len(state_data_sorted)//2])
            second_half = len(state_data_sorted[len(state_data_sorted)//2:])
            trend_delta = second_half - first_half  # Positive = increasing
        else:
            trend_delta = 0
        
        # Fatalities for additional context
        fatalities = state_data['FATALITIES'].sum() if 'FATALITIES' in state_data.columns else 0
        
        indicators_by_state[admin1] = {
            'incidents': total_events,
            'causes_pct': causes_pct,
            'actors': num_actors,
            'trend_delta': trend_delta,
            'high_risk_events': high_risk_events,
            'fatalities': int(fatalities),
            'fatality_rate': fatalities / max(total_events, 1)
        }
    
    return indicators_by_state


def normalize_to_10(values):
    """Normalize to 0-10 scale"""
    if len(values) == 0 or values.max() == values.min():
        return np.ones_like(values) * 5.0
    return 10.0 * (values - values.min()) / (values.max() - values.min())


def calculate_proneness_score(incidents, causes, actors, trend, climate):
    """
    Combined weighted score:
    - incidents (35%): frequency of all events
    - causes (30%): % of high-risk causes
    - actors (20%): # of distinct parties
    - trend (15%): recent change
    - climate: context (separate weighting)
    """
    score = (
        WEIGHTS['incidents'] * incidents +
        WEIGHTS['causes'] * causes +
        WEIGHTS['actors'] * actors +
        WEIGHTS['trend'] * trend +
        WEIGHTS['climate'] * climate
    )
    return round(min(10.0, max(0.0, score)), 2)


def main():
    print("=" * 70)
    print("âœ… CONFLICT PRONENESS v2 - ALL 4 INDICATORS")
    print("=" * 70)

    # Load ACLED with causes
    print(f"\nðŸ“¥ Loading ACLED data from: {ACLED_FILE}")
    df_acled = pd.read_csv(ACLED_FILE)
    df_acled['event_date'] = pd.to_datetime(df_acled['event_date'])
    print(f"   Events: {len(df_acled):,}")

    # Load climate data
    print(f"\nðŸ“¥ Loading climate data from: {CLIMATE_FILE}")
    df_climate = pd.read_csv(CLIMATE_FILE)
    print(f"   States: {len(df_climate):,}")

    # Calculate all 4 indicators per state
    print("\nðŸ”„ Calculating 4 indicators (Incidents, Causes, Actors, Trend)...")
    indicators_by_state = calculate_all_4_indicators(df_acled)
    print(f"   âœ… Calculated for {len(indicators_by_state)} states")

    # Build results dataframe
    print("\nðŸ”„ Computing Conflict Proneness scores...")
    results = []
    
    for _, climate_row in df_climate.iterrows():
        admin1_name = str(climate_row.get('ADM1_NAME', '')).strip()
        
        # Get indicators for this state
        ind = indicators_by_state.get(admin1_name, {
            'incidents': 0,
            'causes_pct': 0,
            'actors': 1,
            'trend_delta': 0,
            'high_risk_events': 0,
            'fatalities': 0,
            'fatality_rate': 0.0
        })
        
        results.append({
            'ADM1_NAME': admin1_name,
            'region': admin1_name,
            # 4 INDICATORS
            'incidents': ind['incidents'],
            'causes_pct': ind['causes_pct'],
            'num_actors': ind['actors'],
            'trend_delta': ind['trend_delta'],
            'high_risk_events': ind['high_risk_events'],
            # Additional metrics
            'fatalities': ind['fatalities'],
            'fatality_rate': ind['fatality_rate'],
            'climate_risk_score': float(climate_row.get('climate_risk_score', 0)),
            'cdi_category': climate_row.get('cdi_category', 'UNKNOWN'),
            # Normalized (for calculation)
            '_incidents_norm': 0,
            '_causes_norm': 0,
            '_actors_norm': 0,
            '_trend_norm': 0,
            '_climate_norm': 0,
        })
    
    df_results = pd.DataFrame(results)
    
    # Normalize all components
    print("   Normalizing components to 0-10...")
    df_results['_incidents_norm'] = normalize_to_10(df_results['incidents'].values.astype(float))
    df_results['_causes_norm'] = normalize_to_10(df_results['causes_pct'].values.astype(float))
    df_results['_actors_norm'] = normalize_to_10(df_results['num_actors'].values.astype(float))
    df_results['_trend_norm'] = normalize_to_10(
        (df_results['trend_delta'].values + abs(df_results['trend_delta'].values.min())).astype(float)
    )
    df_results['_climate_norm'] = normalize_to_10(df_results['climate_risk_score'].values.astype(float))
    
    # Calculate final CP score
    print("   Computing weighted scores...")
    df_results['conflict_proneness'] = df_results.apply(
        lambda row: calculate_proneness_score(
            row['_incidents_norm'],
            row['_causes_norm'],
            row['_actors_norm'],
            row['_trend_norm'],
            row['_climate_norm']
        ),
        axis=1
    )
    
    # Assign level
    def get_proneness_level(score):
        if score >= 8: return "EXTREME"
        elif score >= 6: return "VERY HIGH"
        elif score >= 4: return "HIGH"
        elif score >= 2: return "MODERATE"
        else: return "LOW"
    
    df_results['proneness_level'] = df_results['conflict_proneness'].apply(get_proneness_level)
    df_results = df_results.sort_values('conflict_proneness', ascending=False)
    
    # Display results
    print("\nðŸ“‹ TOP 10 Conflict Proneness (using ALL 4 indicators):")
    print(f"   {'Region':<20} {'CP':>8} {'Level':>12} {'Incidents':>10} {'Causes%':>10} {'Actors':>8} {'Trend':>8}")
    print("   " + "-" * 80)
    
    for _, row in df_results.head(10).iterrows():
        print(f"   {row['ADM1_NAME']:<20} {row['conflict_proneness']:>8.1f} "
              f"{row['proneness_level']:>12} {row['incidents']:>10} "
              f"{row['causes_pct']:>10.1f}% {row['num_actors']:>8} {row['trend_delta']:>+8}")
    
    # Summary statistics
    print("\nðŸ“Š Summary Statistics:")
    print(f"   Mean CP: {df_results['conflict_proneness'].mean():.2f}")
    print(f"   Median CP: {df_results['conflict_proneness'].median():.2f}")
    print(f"   Range: {df_results['conflict_proneness'].min():.2f} - {df_results['conflict_proneness'].max():.2f}")
    print(f"\n   Distribution by Level:")
    for level in ['EXTREME', 'VERY HIGH', 'HIGH', 'MODERATE', 'LOW']:
        count = (df_results['proneness_level'] == level).sum()
        pct = (count / len(df_results)) * 100
        print(f"      {level}: {count:2d} ({pct:5.1f}%)")
    
    # Save
    print(f"\nðŸ’¾ Saving to: {OUTPUT_FILE}")
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    output_cols = [
        'ADM1_NAME', 'region', 'conflict_proneness', 'proneness_level',
        'incidents', 'causes_pct', 'num_actors', 'trend_delta', 'high_risk_events',
        'fatalities', 'fatality_rate', 'climate_risk_score', 'cdi_category'
    ]
    df_results[output_cols].to_csv(OUTPUT_FILE, index=False)
    print(f"   âœ… Saved {len(df_results)} regions")
    
    print("\n" + "=" * 70)
    print("âœ… ALL 4 INDICATORS INCLUDED IN CONFLICT PRONENESS")
    print("=" * 70)

if __name__ == "__main__":
    main()
